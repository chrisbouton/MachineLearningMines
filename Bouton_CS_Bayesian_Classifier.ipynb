{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSCI 470 Activities and Case Studies\n",
    "\n",
    "1. For all activities, you are allowed to collaborate with a partner. \n",
    "1. For case studies, you should work individually and are **not** allowed to collaborate.\n",
    "\n",
    "By filling out this notebook and submitting it, you acknowledge that you are aware of the above policies and are agreeing to comply with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some considerations with regard to how these notebooks will be graded:\n",
    "\n",
    "1. Cells in which \"# YOUR CODE HERE\" is found are the cells where your graded code should be written.\n",
    "2. In order to test out or debug your code you may also create notebook cells or edit existing notebook cells other than \"# YOUR CODE HERE\". We actually highly recommend you do so to gain a better understanding of what is happening. However, during grading, **these changes are ignored**. \n",
    "2. You must ensure that all your code for the particular task is available in the cells that say \"# YOUR CODE HERE\"\n",
    "3. Every cell that says \"# YOUR CODE HERE\" is followed by a \"raise NotImplementedError\". You need to remove that line. During grading, if an error occurs then you will not receive points for your work in that section.\n",
    "4. If your code passes the \"assert\" statements, then no output will result. If your code fails the \"assert\" statements, you will get an \"AssertionError\". Getting an assertion error means you will not receive points for that particular task.\n",
    "5. If you edit the \"assert\" statements to make your code pass, they will still fail when they are graded since the \"assert\" statements will revert to the original. Make sure you don't edit the assert statements.\n",
    "6. We may sometimes have \"hidden\" tests for grading. This means that passing the visible \"assert\" statements is not sufficient. The \"assert\" statements are there as a guide but you need to make sure you understand what you're required to do and ensure that you are doing it correctly. Passing the visible tests is necessary but not sufficient to get the grade for that cell.\n",
    "7. When you are asked to define a function, make sure you **don't** use any variables outside of the parameters passed to the function. You can think of the parameters being passed to the function as a hint. Make sure you're using all of those variables.\n",
    "8. Finally, **make sure you run \"Kernel > Restart and Run All\"** and pass all the asserts before submitting. If you don't restart the kernel, there may be some code that you ran and deleted that is still being used and that was why your asserts were passing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: Bayesian classifier\n",
    "\n",
    "## Part 1: A Bayesian classifier and performance evaluation\n",
    "\n",
    "In this case study you will:\n",
    "1. Build, train, and test a Bayesian classifier. This will increase your understanding of parametric models for supervised learning.\n",
    "2. Implement the model as a Python class, in a manner similar to those of scikit-learn. This will improve you understanding of what goes on under the hood of scikit-learn models.\n",
    "3. Evaluate performance of your Bayesian classifer, but also of some \"foolish\" classifiers. This will alert you to the sometimes misleadingly high performance scores a model might give, even when it has not learning any relationship between features and targets.\n",
    "\n",
    "### In this Part 1 notebook you will focus solely on the Bayesian classifier and its evaluation. In the Part 2 notebook you will build the foolish classifiers and compare evaluation results with those of the Bayesian classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bayesian classifier\n",
    "\n",
    "In this course you have been introduced to one particular type of Bayesian classifier--the Naive Bayes classifer. In that model, it is assumed that all data features are independent of one another, thus substantially reducing the complexity of the posterior probability equation. In this notebook we will not assume independence but we will assume that feature distributions are multivariate Gaussian with no covariance between features--i.e., the covariance matrix is a diagonal matrix. For a given class/label, just think of blobs of samples in n-dimensional space, with different standard deviations (\"widths\") in each dimension and no \"diagonal\" aspect to the blobs--like in the 2D distribution in the image below, which has different standard deviations in the vertical and horizontal directions, but no covariance between them.\n",
    "\n",
    "| ![A 2D Gaussian distribution with diagonal covariance matrix, fitted to noisy data.](./2d_noisy_gaussian.png) |\n",
    "|:--:|\n",
    "| A 2D Gaussian distribution with diagonal covariance matrix, fitted to noisy data. |\n",
    "\n",
    "Recall our Bayesian formulation of a supervised learning classification problem. For class $y$ and feature vector $\\mathbf{x}$,\n",
    "\n",
    "$$P(y|\\mathbf{x}) = \\frac{P(\\mathbf{x}|y)P(y)}{P(\\mathbf{x})}$$\n",
    "\n",
    "For a given feature vector, $\\mathbf{x}$, our goal is to find the label $y$ that gives the largest value for $P(y|\\mathbf{x})$. Because $\\mathbf{x}$ is a fixed sample, $P(\\mathbf{x})$ is a constant, and this goal is equivalent to finding the label $y$ that maximizes $P(\\mathbf{x}|y)P(y)$. Thus, we must use our training set to estimate $P(\\mathbf{x}|y)$ and $P(y)$, and save that information for when we use the model to make class predictions from features.\n",
    "\n",
    "We will assume that for a given class, $y$, the distribution $P(\\mathbf{x}|y)$ is Gaussian, with covariance between features equal to 0. Furthermore, we will work with data that has only two features, $x_1$ and $x_2$, and can thus write our probabilities as:\n",
    "\n",
    "$$ P(x_1,x_2|y)=\\frac{ exp\\Big(-(\\frac{{(x_1-\\mu_{y,1})}^2}{\\sigma_{y,1}^2} + \\frac{{(x_2-\\mu_{y,2})}^2}{\\sigma_{y,2}^2}) /2\\Big) }{2\\pi\\sigma_{y,1}\\sigma_{y,2}}  $$\n",
    "\n",
    "where $\\mu_{y,k}$ and $\\sigma_{y,k}$ are the mean and standard deviation of the $k$th feature for samples in class $y$, respectively. Thus, our final equation for our model's prediction, $\\tilde{y}$ is:\n",
    "\n",
    "$$ \\tilde{y} = \\underset{y}{\\operatorname{argmax}} \\Bigg[\\frac{ exp\\Big(-(\\frac{{(x_1-\\mu_{y,1})}^2}{\\sigma_{y,1}^2} + \\frac{{(x_2-\\mu_{y,2})}^2}{\\sigma_{y,2}^2}) /2\\Big) }{2\\pi\\sigma_{y,1}\\sigma_{y,2}} P(y) \\Bigg] $$\n",
    "\n",
    "\n",
    "__The above equation is your model, and you will use training data to estimate the ${P(y)}$ and the $\\mu$ and $\\sigma$ parameters, and the equation itself to make predictions.\"__ It may look complicated, but don't worry, we'll guide you through the coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model's Python class\n",
    "\n",
    "You will create a Python class from scratch (aside from the skeleton we have provided) that will implement three methods that are part of most scikit-learn model classes:\n",
    "\n",
    "`fit(X, y)` - Trains the model using features X and label y, and stores the learned (fitted) model parameters as class object attributes.\n",
    "\n",
    "`predict(X)` - Using the stored model parameters, predicts labels for features X, and returns them.\n",
    "\n",
    "`fit_predict(X, y)` - Sequentially performs the actions of `fit()` and `predict()`, storing learned model parameters and using those parameters to compute and return its predictions __for the same__ features, X, that are used when fitting. Not all scikit-learn models implement this method. It is often just a convenience function that literally calls `fit()` and then `predict()`, but some scikit-learn models may use a distinct implementation that is more computationally efficient than sequential `fit()` and `predict()` calls. Note that this is not a substitute for splitting your data into train/val/test sets, as `fit_predict()` does not do data splitting.\n",
    "\n",
    "Before you start coding your model class, `BayesClassifier`, keep in mind the manner in which it will be used...\n",
    "\n",
    "```python\n",
    "# A user instantiates the model class, indicating how many classes there\n",
    "# are in the initialization call.\n",
    "bayes_clf = BayesClassifer(n_classes=3)\n",
    "\n",
    "# The user then uses the class object to train on a subset of their data.\n",
    "# In this case they'll obtain the predictions for the training set as well.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "y_pred_train = bayes_clf.fit_predict(X_train, y_train)\n",
    "\n",
    "# The user then makes predictions for the test set.\n",
    "y_pred_test = bayes_clf.predict(X_test)\n",
    "\n",
    "# Finally, the user computes evaluation metric scores for y_pred_train\n",
    "# and y_pred_test (we'll discuss this later in the notebook).\n",
    "```\n",
    "\n",
    "A skeleton of your code is in the cell below, along with guiding comments. Note that typically a developer writes a lot of code that ensures that the user is calling methods with necessary and sufficient arguments, of the appropriate type and range. We will ignore that but you are welcome to include such safechecks (e.g., `assert` statements).\n",
    "\n",
    "Write code for each of the methods of the class, implementing the Bayesian classifier as described above, for data with 2 and only 2 features. Note that the number of classes is a variable specified by the user--__you can assume that labels are integers numbered from 0 to N-1, for N classes.__ For example, if the user specifies that `n_classes=4` then you can assume they will provide a numpy array of labels that looks like `y=np.array([2,3,1,1,0,2,3,3])`. Labels __will not__ be of some other format, such as \"red\", \"blue\", \"green\".\n",
    "\n",
    "__You may implement the methods using native/raw python and the math and/or numpy modules. You may not use scikit-learn, however. Use of numpy is suggested.__\n",
    "\n",
    "`numpy.where()`: As hinted in the skeleton code below, during fitting, you'll need to find all the samples that belong to a given class, and then do something with that subset of samples (e.g., compute the mean). One way of doing that is by using `np.where()` to find the array indicies of the values that meet that criterion, and then index your feature array with those indices, to work on that subset of sample. The snippet of code below demonstrates its usage.\n",
    "\n",
    "```python\n",
    "In [1]: import numpy as np \n",
    "   ...: np.random.seed(42) \n",
    "   ...:                                                                                                                         \n",
    "\n",
    "In [2]: # Create simple data  \n",
    "   ...: labels = np.array([0, 1, 2, 1, 1, 0, 2])  \n",
    "   ...: features = np.random.randint(0, high=10, size=len(labels))  \n",
    "   ...: print(features)  \n",
    "   ...:                                                                                                                         \n",
    "[6 3 7 4 6 9 2]\n",
    "\n",
    "In [3]: # Find the indices of samples of class/label 1. \n",
    "   ...: # Note that np.where() returns a tuple of numpy arrays, even \n",
    "   ...: # if the input to np.where() is only 1-dimensional. So you \n",
    "   ...: # need to access the indices you want by extracting the \n",
    "   ...: # 0th item of the tuple, using the results[0] syntax. \n",
    "   ...: idx = np.where(labels==1)[0] \n",
    "   ...: print(idx) \n",
    "   ...: print(len(idx))  \n",
    "   ...:                                                                                                                         \n",
    "[1 3 4]\n",
    "3\n",
    "\n",
    "In [4]: # Compute the minimum feature value, for samples of class 1  \n",
    "   ...: print(features[idx])  \n",
    "   ...: min_val = np.min(features[idx])  \n",
    "   ...: print(min_val) \n",
    "   ...:                                                                                                                         \n",
    "[3 4 6]\n",
    "3\n",
    "\n",
    "In [5]: # You could even do it all in one line..  \n",
    "   ...: min_val = np.min(features[np.where(labels==1)[0]])  \n",
    "   ...: print(min_val) \n",
    "   ...:                                                                                                                         \n",
    "3\n",
    "```\n",
    "\n",
    "As a final reminder, you are implementing a type of Bayesian classifier, but you are __not__ implementing a Naive Bayes classifier. A Gaussian Naive Bayes classifier would treat $P(x_1,x_2|y)$ as the product of two one-dimensional Gaussian instead: $P(x_1|y)P(x_2|y)$. Such a distribution has more of a rectangular look versus the elliptical look of the image in the cell above. You are welcome to examine scikit-learn's source code for the Naive Bayes classifier ([GaussianNB](https://github.com/scikit-learn/scikit-learn/blob/6c566da8c99b4908a549aeb659cd4b1124bc2448/sklearn/naive_bayes.py#L128)), but copying the code will not give identical results. If you are not an advanced Python user, don't worry if the scikit-learn source code is overwhelming. You're code can be much simpler, and you are probably better off ignoring the scikit-learn code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef12cbaa8f11a7c17d9496ca2dfcf38a",
     "grade": false,
     "grade_id": "BayesClassifier",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Implement the three methods of your Bayesian classifier.\n",
    "## YOU MAY NOT USE SCIKIT-LEARN IN THIS CELL.\n",
    "\n",
    "class BayesClassifier():\n",
    "    def __init__(self, n_classes):\n",
    "        # Store the number of classes as a class attribute\n",
    "        self.n_classes=n_classes\n",
    "        self.means = []\n",
    "        self.variances = []\n",
    "        self.seperated_classes = {}\n",
    "        # You may initialize other variables here if you want to,\n",
    "        # such as an (empty) array for storing feature means\n",
    "        # and variances, though it's not truly necessary.\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "                \n",
    "        \n",
    "    def fit(self, features, labels):\n",
    "        X = features\n",
    "        y = labels\n",
    "        \n",
    "        #𝑃(𝑥1,𝑥2|𝑦)=𝑒𝑥𝑝(−((𝑥1−𝜇𝑦,1)2𝜎2𝑦,1+(𝑥2−𝜇𝑦,2)2𝜎2𝑦,2)/2)2𝜋𝜎𝑦,1𝜎𝑦,2\n",
    "        # features - a numpy array of shape (n_samples, n_features==2)\n",
    "        # labels - a numpy array of shape (n_samples,)\n",
    "        #\n",
    "        # This method does not return/output anything.\n",
    "        \n",
    "        # Use X and y to fit your model parameters.\n",
    "        # For each of the 0 to self.n_classes-1 classes, you should:\n",
    "        # 1. Determine which samples belong to that class, e.g., use np.where().\n",
    "        # 2. Compute an estimate of the prior probability P(class), as the\n",
    "        #    number of samples of that class, divided by the total number of samples.\n",
    "        #    Store that value as an attribute, i.e., a variable that start with \"self.\"\n",
    "        #    Note that you'll likely want to store the prior probabilities in a\n",
    "        #    single list or array, of length n_classes.\n",
    "        \n",
    "        # 3. Compute the mean and variance for both features, for those samples.\n",
    "        #    You may use numpy.mean() and numpy.var()\n",
    "        # 4. Store the means and variances as a class attribute, i.e., a\n",
    "        #    variable that start with \"self.\". Again, you'll likely want to\n",
    "        #    stores the means in a list or array. Same for the variances. You will\n",
    "        #    have n_features*n_classes==2*n_classes means (and variances).\n",
    "        # You may name your attribute variables anything that you wish, as allowed by python.\n",
    "        \n",
    "        # As a reminder, if you use the range() function to loop over\n",
    "        # the class labels [0, 1, 2, ...] recall that range() excludes the\n",
    "        # value of the argument you give it. That is, range(4) will iterate\n",
    "        # over 0, 1, 2, and 3. It will exclude 4.\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        self.priors = np.zeros(self.n_classes)\n",
    "        self.means = np.zeros((self.n_classes,2))\n",
    "        self.vars = np.zeros((self.n_classes,2))\n",
    "                              \n",
    "        n_samples = features.shape\n",
    "        print(n_samples)\n",
    "                              \n",
    "        for i_class in range(self.n_classes):\n",
    "            \n",
    "            idx = np.where(labels==i_class)[0]\n",
    "            print(len(idx))\n",
    "            #number of samples of class i, , divided by notal number of samples\n",
    "            \n",
    "            self.priorProb[i_class] = len(idx)/n_samples\n",
    "            \n",
    "            self.means[i_class, :] = np.mean(features[idx, :],axis =0)\n",
    "            print(self.means)\n",
    "            self.vars[i_class, :] = np.vars(features[idx, : ],axis= 0)\n",
    "            print(self.vars)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#         for i in range(len(X)):\n",
    "#             feature_values = X[i]\n",
    "#             class_name = y[i]\n",
    "            \n",
    "#             if class_name not in self.seperated_classes:\n",
    "#                 self.seperated_classes[class_name] = []\n",
    "#             self.seperated_classes[class_name].append(feature_values)\n",
    "#         self.stat_info = {}\n",
    "#         for feature in X:\n",
    "#             self.stat_info = {'std':np.std(feature),'mean':np.mean(feature)}\n",
    "        \n",
    "#         self.class_summary = {}\n",
    "        \n",
    "#         for class_name, feature_values in self.seperated_classes.items():\n",
    "#             self.class_summary[class_name]= {\n",
    "#                 'prior_proba':len(feature_values)/len(X), 'summary': [i for i in self.stat_info[feature_values]\n",
    "#             }\n",
    "#         #raise NotImplementedError()\n",
    "\n",
    "        \n",
    "    def predict(self, features):\n",
    "        pass\n",
    "        # features - a numpy array of shape (n_samples, n_features==2)\n",
    "        #\n",
    "        # Returns an array of predictions\n",
    "        \n",
    "        # Use your fitted model parameters to make label predictions for\n",
    "        # the samples in 'features'.\n",
    "        # 1. For each of the 0 to self.n_classes-1 classes, you should compute\n",
    "        #    P(X|y=class)*P(y=class), for all samples, and store those values.\n",
    "        # 2. For each/all samples, find the argmax across the n_class classes.\n",
    "        #    You may use numpy.argmax().\n",
    "        # 3. Return those argmax values, which are the label predictions.\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "    def fit_predict(self, features, labels):\n",
    "        pass\n",
    "        # features - a numpy array of shape (n_samples, n_features==2)\n",
    "        # labels - a numpy array of shape (n_samples,)\n",
    "        #\n",
    "        # Returns an array of predictions\n",
    "        \n",
    "        # Fit your model by calling self.fit(features, labels)\n",
    "        # Then make predictions by calling self.predict(features)\n",
    "        # Finally, return those predictions.\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below does a coarse check of your implementation of the BayesClassifier class. Unless you are a Python and numpy superstar, it will likely fail on your first try. It may not give you any meaningful feedback to help you debug your code.\n",
    "\n",
    "To help with debugging, don't hesistate to:\n",
    "1. Put print statements in your code above, to show you the contents of variables and ensure they hold the values you expect. Also print out helpful info such as a variables type (e.g., are you sure it's a numpy array? Or is it a list?... `print(type(my_variable))`, shape: `print(my_variable.shape)`, and length: `print(len(my_variable))`. Note that the output of the print statements will appear below the cell in which you classifier is instantiated, or one of its methods is called. It will not appear under the cell in which the class is defined (above).\n",
    "2. Create a new cell below, and create simple data you can use to test your classifier (as in the autograder cell below).\n",
    "3. If you instantiate your class, you can then view its attributes and their values as shown below:\n",
    "```python\n",
    "# Create object\n",
    "clf = BayesClassifier(n_classes=4)\n",
    "# print out the names of its attributes\n",
    "print(clf.__dict__.keys())\n",
    "# If an attribute is named \"means\" you can print out its values...\n",
    "print(clf.means)\n",
    "```\n",
    "Keep in mind that depending on how you implemented your class, some attributes may not exist until the `fit()` method is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8f084ba4110d0e5ca30ec2e10397e36",
     "grade": true,
     "grade_id": "BayesClassifierTests",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-adaedda54c37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Test fit() and predict()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBayesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-0a32dc7e4c69>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, labels)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;31m#number of samples of class i, , divided by notal number of samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpriorProb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi_class\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'int' and 'tuple'"
     ]
    }
   ],
   "source": [
    "# Autograder: Create a few samples from 3 classes, with high class separation\n",
    "n_classes = 3\n",
    "y = np.array([0, 0, 1, 1, 2, 2])\n",
    "X = np.array([[-1, 1], [1, -1], [2, 5], [5, 2], [-2, -5], [-5, -2]])\n",
    "\n",
    "# Test fit() and predict()\n",
    "clf = BayesClassifier(n_classes)\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X)\n",
    "assert np.array_equal(y, y_pred)\n",
    "\n",
    "# Test fit_predict()\n",
    "y_pred = clf.fit_predict(X, y)\n",
    "assert np.array_equal(y, y_pred)\n",
    "\n",
    "# Try with 4 classes also\n",
    "n_classes = 4\n",
    "y = np.array([0, 0, 1, 1, 2, 2, 3, 3])\n",
    "X = np.array([[-1, 1], [1, -1], [2, 5], [5, 2], [-2, -5], [-5, -2], [10, 11], [11, 10]])\n",
    "\n",
    "# Test fit() and predict()\n",
    "clf = BayesClassifier(n_classes)\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X)\n",
    "assert np.array_equal(y, y_pred)\n",
    "\n",
    "# Test fit_predict()\n",
    "y_pred = clf.fit_predict(X, y)\n",
    "assert np.array_equal(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and visualization\n",
    "\n",
    "Now that you've completed all that hard work, let's try it out, and visual some results. Since we are only using two features, we can easily display results in 2D plots.\n",
    "\n",
    "Below, we create the usual synthetic \"blobs\" of samples, with class labels. We will train our model and then create a colormap that should the classifiers boundaries between classes. In most real-world cases your feature dimensionality will be too high to create such a colormap, but we do it here for edification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random samples of three classes, with samples drawn from multivariate Gaussian distributions\n",
    "np.random.seed(42)\n",
    "n1 = 10\n",
    "mean1 = [0, 1]\n",
    "cov1 = [[1, 0], [0, 1]]\n",
    "n2 = 20\n",
    "mean2 = [3, 2]\n",
    "cov2 = [[0.1, 0], [0, 1]]\n",
    "n3 = 70\n",
    "mean3 = [1, 3]\n",
    "cov3 = [[1, 0], [0, 0.5]]\n",
    "X = [np.random.multivariate_normal(mean1, cov1, size=n1),\n",
    "     np.random.multivariate_normal(mean2, cov2, size=n2),\n",
    "     np.random.multivariate_normal(mean3, cov3, size=n3),\n",
    "    ]\n",
    "X = np.concatenate(X, axis=0)\n",
    "y = np.array([0]*n1 + [1]*n2 + [2]*n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's train a model on the data set, then visualize the predictions,\n",
    "# as a subjective check. The predicted sample labels, plotted on the left, should\n",
    "# be color-coded much like the ground truth samples labels, plotted on the right,\n",
    "# except in regions were ground truth classes \"overlap.\"\n",
    "#\n",
    "# We're not yet concerned with evaluating a trained model's performance (on a\n",
    "# validation or test set), so we'll just use all our data for training.\n",
    "\n",
    "clf = BayesClassifier(n_classes=3)\n",
    "y_pred = clf.fit_predict(X, y)\n",
    "\n",
    "# Plot our synthetic data\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.clf()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='o', c=y, s=50, edgecolor='k')\n",
    "plt.title(\"Training data ground truth labels\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.axis([-2, 4, -1, 5])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='o', c=y_pred, s=50, edgecolor='k')\n",
    "plt.title(\"Training data predicted labels\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.axis([-2, 4, -1, 5])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets create a map of the classification regions, and boundaries between them.\n",
    "# To do so we'll create a set of features (x1 and x2 values) that densely span the space,\n",
    "# get predictions for those features, and then plot the predicted labels as a colormap.\n",
    "x1 = np.arange(-2, 4, 0.01)\n",
    "x2 = np.arange(-1, 5, 0.01)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "X_dense = np.stack((X1.flatten(), X2.flatten()), axis=1)\n",
    "y_dense = clf.predict(X_dense)\n",
    "y_dense = np.reshape(y_dense, (len(x1), len(x2)))\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(y_dense, aspect='auto')\n",
    "plt.grid(False)\n",
    "plt.axis('off')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('x1')\n",
    "plt.xlabel('x2')\n",
    "_ = plt.title('Classifier decision boundaries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The impact of the class prior distribution\n",
    "\n",
    "If you wrote your classifier code correctly, all the images above should look commensurate, and hopefully you now have a better understanding of both Bayesian classifiers as well as how sckit-learn models are implemented. Great! But before we move on to evaluation metrics, let's do one more sanity check.\n",
    "\n",
    "Remember that the Bayesian classifier takes into account the prior distribution of classes--that is, the $P(y)$ term in $P(\\bar{x}|y)P(y)$. Imagine we have two classes with nearly the same feature distributions (means and variances) but one of those classes has notably fewer samples than the other class, i.e., it's prior is much lower. In that case, our Bayesian classifier should nearly always select the class that is more prevalent in the training set, since the $P(\\bar{x}|y)$ terms are about the same for both classes. Let's see what your classifier does in that situation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random samples of two classes with identical feature distributions,\n",
    "# but with many more samples of class 1 than class 2\n",
    "np.random.seed(42)\n",
    "XX = [np.random.multivariate_normal([0, 0], [[1, 0], [0, 1]], size=100),\n",
    "     np.random.multivariate_normal([0, 0], [[1, 0], [0, 1]], size=50),\n",
    "    ]\n",
    "XX = np.concatenate(XX, axis=0)\n",
    "yy = np.array([0]*100 + [1]*50)\n",
    "\n",
    "# Let train, predict, and plot, as before...\n",
    "clf = BayesClassifier(n_classes=2)\n",
    "yy_pred = clf.fit_predict(XX, yy)\n",
    "\n",
    "# Plot our synthetic data\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.clf()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(XX[:, 0], XX[:, 1], marker='o', c=yy, s=50, edgecolor='k')\n",
    "plt.title(\"Training data ground truth labels\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(XX[:, 0], XX[:, 1], marker='o', c=yy_pred, s=50, edgecolor='k')\n",
    "plt.title(\"Training data predicted labels\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all is well, you should see that the classifier predicted nearly all the samples to be of just one class--the class that had twice as many samples in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now, let's split our data into training and test sets, train the model, and then evaluate it. In this section you'll assess and score the model's test set predictions using tools we've discussed in the course:\n",
    "- [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "- [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "- [precision, recall, and F-score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html).\n",
    "\n",
    "__We'll work with the 3-class synthetic data we initially created in this notebook.__\n",
    "\n",
    "You can use scikit-learn for performing the evaluation, but should continue to use your BayesClassifier as the model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data into train and test sets.\n",
    "# Note that our data samples were ordered by class labels. We always want to randomly\n",
    "# shuffle the sample ordering before splitting data in to train/test sets. The\n",
    "# train_test_split() function does this for us, by default.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d60fc269b8119e00119985f91d29e292",
     "grade": false,
     "grade_id": "Prediction",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# In this cell you should do the following:\n",
    "#\n",
    "# 1. Instantiate a new Bayesian classifier for a 3-class model, naming the classifier 'clf'.\n",
    "# 2. Train your model on X_train and y_train and get predictions for the X_train features,\n",
    "#    saving these to the variable 'y_pred_train'.\n",
    "# 3. Use your model to make test set predictions for the X_test features, saving them\n",
    "#    to the variable 'y_pred_test'.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91fb6f61eb0c0a0a253fb722f536a694",
     "grade": true,
     "grade_id": "PredictionTest",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder: Check that the number of model's predictions are as expected\n",
    "assert np.sum(y_pred_test==y_test)==18\n",
    "assert np.sum(y_pred_train==y_train)==76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40cf8df7db7b2ba2b5823a0f9b64d50d",
     "grade": false,
     "grade_id": "Evaluation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# In this cell you should use scikit-learn to get the confusion matrix,\n",
    "# accuracy, precision, recall, and F-score. You should have two of each, one\n",
    "# for the training set and one for the test set.\n",
    "#\n",
    "# Name your variables:\n",
    "#   cm_train, acc_train, prec_train, rec_train, fs_train\n",
    "#   cm_test,  acc_test,  prec_test,  rec_test,  fs_test\n",
    "#\n",
    "# Note that precision_recall_fscore_support() returns four values. You do not\n",
    "# need the 'support' value.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3229b53e7800cbeb8ca5515baecaf512",
     "grade": true,
     "grade_id": "EvaluationTest",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.sum(cm_test)==len(y_test)\n",
    "assert np.sum(cm_train)==len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the confusion tables and the scores. Take a look at them. Do the seem in alignment with the plots we saw before, for the model trained on all the data? If not, review your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion table: train')\n",
    "print(cm_train)\n",
    "print('\\nConfusion table: test')\n",
    "print(cm_test)\n",
    "print(f'\\nAccuracies: train={acc_train}, test={acc_test}')\n",
    "print(f'\\nPrecisions:   train={prec_train}, test={prec_test}')\n",
    "print(f'Recalls:      train={rec_train}, test={rec_test}')\n",
    "print(f'F-scores:     train={fs_train}, test={fs_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's it for Part 1! In Part 2 you will...\n",
    "\n",
    "- Build a couple \"foolish\" classifiers that base their predictions only on some aspect of the class prior probabilites, ignoring the data features altogether.\n",
    "- Write a function that computes one or more evaluation metrics using numpy rather than scikit-learn.\n",
    "- Compute evaluation metrics for both the foolish classifiers and a Bayesian classifier.\n",
    "- Compare results across classifiers, and discuss why the foolish classifier(s) sometimes give misleadingly high scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35c02446ada971330235203f8d3b177f",
     "grade": false,
     "grade_id": "cell-d45e75d8071c765c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc89e0660ccb53529a249ada6cc1a0cd",
     "grade": false,
     "grade_id": "cell-fb93624c53422815",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def feedback():\n",
    "    \"\"\"Provide feedback on the contents of this exercise\n",
    "    \n",
    "    Returns:\n",
    "        string\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51c4d2a5734ab18322474a6f62fb5382",
     "grade": true,
     "grade_id": "cell-10ee4b2b9ba4be3d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7e52b5d11b2b6ea45dc69eef8d810a65927b3a0f6b86433b4140ef9a1427344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
